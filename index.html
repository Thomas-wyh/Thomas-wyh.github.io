<html lang="en"><head>
    <meta charset="UTF-8">
    <title></title>
<style id="system" type="text/css">h1,h2,h3,h4,h5,h6,p,blockquote {    margin: 0;    padding: 0;}body {    font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", Arial, sans-serif;    font-size: 13px;    line-height: 18px;    color: #737373;    margin: 10px 13px 10px 13px;}a {    color: #0069d6;}a:hover {    color: #0050a3;    text-decoration: none;}a img {    border: none;}p {    margin-bottom: 9px;}h1,h2,h3,h4,h5,h6 {    color: #404040;    line-height: 36px;}h1 {    margin-bottom: 18px;    font-size: 30px;}h2 {    font-size: 24px;}h3 {    font-size: 18px;}h4 {    font-size: 16px;}h5 {    font-size: 14px;}h6 {    font-size: 13px;}hr {    margin: 0 0 19px;    border: 0;    border-bottom: 1px solid #ccc;}blockquote {    padding: 13px 13px 21px 15px;    margin-bottom: 18px;    font-family:georgia,serif;    font-style: italic;}blockquote:before {    content:"¬ÅC";    font-size:40px;    margin-left:-10px;    font-family:georgia,serif;    color:#eee;}blockquote p {    font-size: 14px;    font-weight: 300;    line-height: 18px;    margin-bottom: 0;    font-style: italic;}code, pre {    font-family: Monaco, Andale Mono, Courier New, monospace;}code {    background-color: #fee9cc;    color: rgba(0, 0, 0, 0.75);    padding: 1px 3px;    font-size: 12px;    -webkit-border-radius: 3px;    -moz-border-radius: 3px;    border-radius: 3px;}pre {    display: block;    padding: 14px;    margin: 0 0 18px;    line-height: 16px;    font-size: 11px;    border: 1px solid #d9d9d9;    white-space: pre-wrap;    word-wrap: break-word;}pre code {    background-color: #fff;    color:#737373;    font-size: 11px;    padding: 0;}@media screen and (min-width: 768px) {    body {        width: 748px;        margin:10px auto;    }}</style><style id="custom" type="text/css"></style></head>
<body marginheight="0"><h1>Yaohua Wang (ËÄÄÂçé Áéã)</h1>
<div>
<br><table border="0">
  <tbody><tr>
    <td width="20%">
      <img src="figure/logo.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> I am a Senior Algorithm Engineer at <a href="https://damo.alibaba.com/">DAMO Academy of Alibaba Group</a>. 
      Before I joined DAMO, I was an Algorithm Engineer at <a href="https://www.jd.com/">JD</a> until July 2019.
      I received my master's degree from <a href="https://buaa.edu.cn/">Beihang University</a> in 2017.</font><br>
      <font size="2"> My research interests include Graph Learning, Metric Learning and Efficient Deep Learning in Neural Architecture Search with application in Computer Vision.</font><br>
      <font size="2"> <strong>Email</strong>: myslacklife [AT] gmail.com, xiachen.wyh [AT] alibaba-inc.com </font>
    </td>
  </tr>
</tbody></table>
</div>

<h2><font color="#c60b0b"><strong>News</strong></font></h2>
<hr>
<ul>
<li>[2024/09] üåû One paper was accepted to NeurIPS 2024 Spotlight !</li>
<li>[2023/03] üåû Two papers were accepted to CVPR 2023 !</li>
<li>[2022/07] üåû One paper was accepted to NeurIPS 2022 !</li>
<li>[2022/01] üåû One paper was accepted to ICLR 2022 !</li>
</ul>
<h2><font color="#c60b0b">Experiences</font></h2>
<hr>
<ul>
<li>Senior Algorithm Engineer, DAMO Academy of Alibaba Group, 2019-Present</li>
<li>Algorithm Engineer, JD.com, 2017-2019</li>
</ul>
<h2><font color="#c60b0b">Educations</font></h2>
<hr>
<ul>
<li>Master's Degree, Beihang University, 2014-2017</li>
<li>Bachelor's Degree, Central University of Finance and Economics, 2010-2014</li>
</ul>
<h2><strong><a href="https://scholar.google.com.hk/citations?user=TRAwmsgAAAAJ&amp;hl=zh-CN"><font color="#c60b0b">Publications</font></a></strong></h2>
<hr>
<h4><font color="#537abb">Conference</font></h4>
<p></p><div>
  <p></p>
  <p></p><br><table border="0" cellspacing="20">
    <tbody><tr>
      <td width="20%">
        <img src="figure/neurips24-fuseanypart.png" width="100%">
      </td>    <td width="80%">
        <font size="2"> Zheng Yu#, <strong><u>Yaohua Wang# &#x2709;</u></strong>, Siying Cui, Aixi Zhang, Wei-Long Zheng, Senzhang Wang.<br>
          FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images. Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2024. <br>
                      <a href="hhttps://arxiv.org/abs/2410.22771">[Arxiv]</a> <a href="https://openreview.net/forum?id=X2UMdvcmMo">[OpenReview]</a> <a href="https://github.com/thomas-wyh/fuseanypart">[GitHub]</a> <a href="https://neurips.cc/virtual/2024/poster/94797">[Poster]</a> <a href="https://neurips.cc/media/neurips-2024/Slides/94797_pZodHSS.pdf">[Slides]</a> <a href="https://recorder-v3.slideslive.com/#/share?share=95067&s=60241a46-d145-45dd-8e5b-5056b2f6b899">[video]</a><a href="figure/bib/fuseanypart.bib">[bib]</a></font>
        <br>
        <font size="1"><em>A novel diffusion-driven facial parts swapping methods with multiple reference images.</em></font>
      </td>
    </tr>
  </tbody></table>
  </div>
  
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="figure/cvpr23-deepmad.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> Xuan Shen#, <strong><u>Yaohua Wang#</u></strong>, Ming Lin, Yilun Huang, Hao Tang, Xiuyu Sun, Yanzhi Wang.<br>
                    DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural Network. Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023. <br>
                    <a href="https://arxiv.org/abs/2303.02165">[Arxiv]</a> <a href="https://openreview.net/forum?id=HCQqTcy2xG">[OpenReview]</a> <a href="https://github.com/alibaba/lightweight-neural-architecture-search">[GitHub]</a> <a href="">[Poster]</a> <a href="">[video]</a><a href="figure/bib/deepmad.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A novel framework termed Mathematical Architecture Design for Deep CNN to design high-performance CNN models in a principled way.</em></font>
    </td>
  </tr>
</tbody></table>
</div>

<p></p>
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="figure/neurips22-QAttention.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> <strong><u>Yaohua Wang</u></strong>, Fangyi Zhang, Ming Lin, Senzhang Wang, Xiuyu Sun, Rong Jin. <br>
                    Robust Graph Structure Learning over Images via Multiple Statistical Tests. Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022. <br>
                    <a href="https://arxiv.org/abs/2210.03956">[Arxiv]</a> <a href="https://openreview.net/forum?id=VVCI8-PYYv">[OpenReview]</a> <a href="https://github.com/Thomas-wyh/B-Attention">[GitHub]</a> <a href="https://nips.cc/media/PosterPDFs/NeurIPS%202022/fdaa09fc5ed18d3226b3a1a00f1bc48c.png">[Poster]</a> <a href="https://neurips.cc/virtual/2022/spotlight/65232">[video-1min]</a> <a href="https://neurips.cc/virtual/2022/poster/54278">[video-5min]</a> <a href="figure/bib/battention.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A novel method for learning robust graph structures in computer vision tasks where graph structures are not available.</em></font>
    </td>
  </tr>
</tbody></table>
</div>

<p></p>
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="figure/iclr22-adanets.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> <strong><u>Yaohua Wang</u></strong>, Yaobin Zhang, Fangyi Zhang, Senzhang Wang, Ming Lin, YuQi Zhang, Xiuyu Sun. <br>
                    Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space. In Proceedings of the International Conference on Learning Representations (<strong>ICLR</strong>), 2022. <br>
                    <a href="https://arxiv.org/abs/2202.03800">[Arxiv]</a> <a href="https://openreview.net/forum?id=QJWVP4CTmW4">[OpenReview]</a> <a href="https://github.com/damo-cv/Ada-NETS">[GitHub]</a> <a href="https://zhuanlan.zhihu.com/p/465791772">[Zhihu]</a> <a href="https://iclr.cc/virtual/2022/poster/6907">[Video]</a> <a href="figure/bib/adanets.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A novel algorithm named Ada-NETS is proposed to construct the clean graph for GCNs to cluster faces in this paper.</em></font>
    </td>
  </tr>
</tbody></table>
</div>

<p></p>
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="figure/cvpr23_soilder.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> Weihua Chen, Xianzhe Xu, Jian Jia, Hao Luo, <strong><u>Yaohua Wang</u></strong>, Xiuyu Sun, Fan Wang, Rong Jin. <br>
                    Beyond Visual Appearance: a Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks. Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023. <br>
                    <a href="https://arxiv.org/abs/2303.17602">[Arxiv]</a> <a href="https://openreview.net/forum?id=Jm07ym2I0w">[OpenReview]</a> <a href="https://github.com/SSL-SOLIDER/SOLIDER">[GitHub]</a> <a href="">[Poster]</a> <a href="">[video]</a><a href="figure/bib/soilder.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A controllable self-supervised learning framework to produce representations with different ratios of semantic information.</em></font>
    </td>
  </tr>
</tbody></table>
</div>

<p></p>
<h4><font color="#537abb">Journal</font></h4>
<ul>
<li><strong><u>Wang Yaohua</u></strong>, LI Zhoujun, HE Yueying, CHAO Wenhan, ZHOU Jianshe. Research on Key Technology of Automatic Essay Scoring  Based on Text Semantic Dispersion. Journal of Chinese Information Processing, 2016. <a href="http://jcip.cipsc.org.cn/CN/Y2016/V30/I6/173">[Paper]</a></li>
<li>Yuqi Zhang, Wei Li, <strong><u>Yaohua Wang</u></strong>, Zhibin Wang, Hao Li. Beyond Classifiers: Remote Sensing Change Detection with Metric Learning[J]. Remote Sensing, 2022, 14(18): 4478.<a href="https://www.mdpi.com/2072-4292/14/18/4478">[Paper]</a></li>
</ul>
<h4><font color="#537abb">Pre-print</font></h4>
<ul>
<li>Ya Wang, Hesen Chen, Fangyi Zhang, <strong><u>Yaohua Wang</u></strong>, Xiuyu Sun, Ming Lin, Hao Li. Fine-Grained AutoAugmentation for Multi-label Classification. <a href="https://arxiv.org/abs/2107.05384">[Arxiv]</a> </li>
<li>Zhang Yuqi, Xu Xianzhe, Chen Weihua, <strong><u>Wang Yaohua</u></strong>, Zhang Fangyi, Wang Fan, Li Hao. 2nd Place Solution to Google Landmark Retrieval 2021. <a href="https://arxiv.org/abs/2110.04294">[Arxiv]</a></li>
</ul>
<h2><strong><a href="https://scholar.google.com.hk/citations?user=TRAwmsgAAAAJ&amp;hl=zh-CN"><font color="#c60b0b">Academic service</font></a></strong></h2>
<h4><font color="#537abb">Reviewer for Conferences</font></h4>
<ul>
<li><strong>CVPR 2024, CVPR 2025</strong></li>
<li><strong>NeurIPS 2023, NeurIPS 2024</strong></li>
<li><strong>ICLR 2024</strong></li>
<li><strong>AAAI 2025</strong></li>
<li><strong>ICML 2024</strong></li>
</ul>
</body></html>
<html lang="en"><head>
    <meta charset="UTF-8">
    <title></title>
<style id="system" type="text/css">h1,h2,h3,h4,h5,h6,p,blockquote {    margin: 0;    padding: 0;}body {    font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", Arial, sans-serif;    font-size: 13px;    line-height: 18px;    color: #737373;    margin: 10px 13px 10px 13px;}a {    color: #0069d6;}a:hover {    color: #0050a3;    text-decoration: none;}a img {    border: none;}p {    margin-bottom: 9px;}h1,h2,h3,h4,h5,h6 {    color: #404040;    line-height: 36px;}h1 {    margin-bottom: 18px;    font-size: 30px;}h2 {    font-size: 24px;}h3 {    font-size: 18px;}h4 {    font-size: 16px;}h5 {    font-size: 14px;}h6 {    font-size: 13px;}hr {    margin: 0 0 19px;    border: 0;    border-bottom: 1px solid #ccc;}blockquote {    padding: 13px 13px 21px 15px;    margin-bottom: 18px;    font-family:georgia,serif;    font-style: italic;}blockquote:before {    content:"¬ÅC";    font-size:40px;    margin-left:-10px;    font-family:georgia,serif;    color:#eee;}blockquote p {    font-size: 14px;    font-weight: 300;    line-height: 18px;    margin-bottom: 0;    font-style: italic;}code, pre {    font-family: Monaco, Andale Mono, Courier New, monospace;}code {    background-color: #fee9cc;    color: rgba(0, 0, 0, 0.75);    padding: 1px 3px;    font-size: 12px;    -webkit-border-radius: 3px;    -moz-border-radius: 3px;    border-radius: 3px;}pre {    display: block;    padding: 14px;    margin: 0 0 18px;    line-height: 16px;    font-size: 11px;    border: 1px solid #d9d9d9;    white-space: pre-wrap;    word-wrap: break-word;}pre code {    background-color: #fff;    color:#737373;    font-size: 11px;    padding: 0;}@media screen and (min-width: 768px) {    body {        width: 748px;        margin:10px auto;    }}</style><style id="custom" type="text/css"></style></head>
<body marginheight="0"><h1>Yaohua Wang (ËÄÄÂçé Áéã)</h1>
<div>
<br><table border="0">
  <tbody><tr>
    <td width="20%">
      <img src="https://thomas-wyh.github.io/image/logo.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> I am a Senior Algorithm Engineer at <a href="https://damo.alibaba.com/">DAMO Academy of Alibaba Group</a>. 
      Before I joined DAMO, I was an Algorithm Engineer at <a href="https://www.jd.com/">JD</a> until July 2019.
      I received my master's degree from <a href="https://buaa.edu.cn/">Beihang University</a> in 2017.</font><br>
      <font size="2"> My research interests include Graph Learning, Metric Learning and Efficient Deep Learning in Neural Architecture Search with application in Computer Vision.</font><br>
      <font size="2"> <strong>Email</strong>: myslacklife [AT] gmail.com, xiachen.wyh [AT] alibaba-inc.com </font>
    </td>
  </tr>
</tbody></table>
</div>

<h2><font color="#c60b0b"><strong>News</strong></font></h2>
<hr>
<ul>
<li>[2023/03] üåû Two papers were accepted to CVPR 2023 !</li>
<li>[2022/07] üåû One paper were accepted to NeurIPS 2022 !</li>
<li>[2022/01] üåû One paper were accepted to ICLR 2022 !</li>
</ul>
<h2><font color="#c60b0b">Experiences</font></h2>
<hr>
<ul>
<li>Senior Algorithm Engineer, DAMO Academy of Alibaba Group, 2019-Present</li>
<li>Algorithm Engineer, JD.com, 2017-2019</li>
</ul>
<h2><font color="#c60b0b">Educations</font></h2>
<hr>
<ul>
<li>Master's Degree, Beihang University, 2014-2017</li>
<li>Bachelor's Degree, Central University of Finance and Economics, 2010-2014</li>
</ul>
<h2><strong><a href="https://scholar.google.com.hk/citations?user=TRAwmsgAAAAJ&amp;hl=zh-CN"><font color="#c60b0b">Publications</font></a></strong></h2>
<hr>
<h4><font color="#537abb">Conference</font></h4>
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="https://thomas-wyh.github.io/image/cvpr23-deepmad.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> Xuan Shen, <strong>Yaohua Wang</strong>, Ming Lin, Yilun Huang, Hao Tang, Xiuyu Sun, Yanzhi Wang.<br>
                    DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural Network. Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023. <br>
                    <a href="https://arxiv.org/abs/2303.02165">[Arxiv]</a> <a href="https://openreview.net/forum?id=HCQqTcy2xG">[OpenReview]</a> <a href="https://github.com/alibaba/lightweight-neural-architecture-search">[GitHub]</a> <a href="">[Poster]</a> <a href="">[video]</a><a href="https://thomas-wyh.github.io/bib/deepmad.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A novel framework termed Mathematical Architecture Design for Deep CNN to design high-performance CNN models in a principled way.</em></font>
    </td>
  </tr>
</tbody></table>
</div>
<p></p>
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="https://thomas-wyh.github.io/image/neurips22-QAttention.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> <strong>Yaohua Wang</strong>, Fangyi Zhang, Ming Lin, Senzhang Wang, Xiuyu Sun, Rong Jin. <br>
                    Robust Graph Structure Learning over Images via Multiple Statistical Tests. Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022. <br>
                    <a href="https://arxiv.org/abs/2210.03956">[Arxiv]</a> <a href="https://openreview.net/forum?id=VVCI8-PYYv">[OpenReview]</a> <a href="https://github.com/Thomas-wyh/B-Attention">[GitHub]</a> <a href="https://nips.cc/media/PosterPDFs/NeurIPS%202022/fdaa09fc5ed18d3226b3a1a00f1bc48c.png">[Poster]</a> <a href="https://neurips.cc/virtual/2022/spotlight/65232">[video-1min]</a> <a href="https://neurips.cc/virtual/2022/poster/54278">[video-5min]</a> <a href="https://thomas-wyh.github.io/bib/battention.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A novel method for learning robust graph structures in computer vision tasks where graph structures are not available.</em></font>
    </td>
  </tr>
</tbody></table>
</div>
<p></p>
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="https://thomas-wyh.github.io/image/iclr22-adanets.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> <strong>Yaohua Wang</strong>, Yaobin Zhang, Fangyi Zhang, Senzhang Wang, Ming Lin, YuQi Zhang, Xiuyu Sun. <br>
                    Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space. In Proceedings of the International Conference on Learning Representations (<strong>ICLR</strong>), 2022. <br>
                    <a href="https://arxiv.org/abs/2202.03800">[Arxiv]</a> <a href="https://openreview.net/forum?id=QJWVP4CTmW4">[OpenReview]</a> <a href="https://github.com/damo-cv/Ada-NETS">[GitHub]</a> <a href="https://zhuanlan.zhihu.com/p/465791772">[Zhihu]</a> <a href="https://iclr.cc/virtual/2022/poster/6907">[Video]</a> <a href="https://thomas-wyh.github.io/bib/adanets.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A novel algorithm named Ada-NETS is proposed to construct the clean graph for GCNs to cluster faces in this paper.</em></font>
    </td>
  </tr>
</tbody></table>
</div>
<p></p>
<p></p><div>
<p></p>
<p></p><br><table border="0" cellspacing="20">
  <tbody><tr>
    <td width="20%">
      <img src="https://thomas-wyh.github.io/image/cvpr23_soilder.png" width="100%">
    </td>    <td width="80%">
      <font size="2"> Weihua Chen, Xianzhe Xu, Jian Jia, Hao Luo, <strong>Yaohua Wang</strong>, Xiuyu Sun, Fan Wang, Rong Jin. <br>
                    Beyond Visual Appearance: a Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks. Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023. <br>
                    <a href="">[Arxiv]</a> <a href="https://openreview.net/forum?id=Jm07ym2I0w">[OpenReview]</a> <a href="https://github.com/SSL-SOLIDER/SOLIDER">[GitHub]</a> <a href="">[Poster]</a> <a href="">[video]</a><a href="https://thomas-wyh.github.io/bib/soilder.bib">[bib]</a></font>
      <br>
      <font size="1"><em>A controllable self-supervised learning framework to produce representations with different ratios of semantic information.</em></font>
    </td>
  </tr>
</tbody></table>
</div>
<p></p>
<h4><font color="#537abb">Journal</font></h4>
<ul>
<li><strong>WANG Yaohua</strong>, LI Zhoujun, HE Yueying, CHAO Wenhan, ZHOU Jianshe. Research on Key Technology of Automatic Essay Scoring  Based on Text Semantic Dispersion. Journal of Chinese Information Processing, 2016. <a href="http://jcip.cipsc.org.cn/CN/Y2016/V30/I6/173">[Paper]</a></li>
<li>Yuqi Zhang, Wei Li, <strong>Yaohua Wang</strong>, Zhibin Wang, Hao Li. Beyond Classifiers: Remote Sensing Change Detection with Metric Learning[J]. Remote Sensing, 2022, 14(18): 4478.<a href="https://www.mdpi.com/2072-4292/14/18/4478">[Paper]</a></li>
</ul>
<h4><font color="#537abb">Pre-print</font></h4>
<ul>
<li>Ya Wang, Hesen Chen, Fangyi Zhang, <strong>Yaohua Wang</strong>, Xiuyu Sun, Ming Lin, Hao Li. Fine-Grained AutoAugmentation for Multi-label Classification. <a href="https://arxiv.org/abs/2107.05384">[Arxiv]</a> </li>
<li>Zhang Yuqi, Xu Xianzhe, Chen Weihua, Wang Yaohua, Zhang Fangyi, Wang Fan, Li Hao. 2nd Place Solution to Google Landmark Retrieval 2021. <a href="https://arxiv.org/abs/2110.04294">[Arxiv]</a></li>
</ul>
<h2><strong><a href="https://scholar.google.com.hk/citations?user=TRAwmsgAAAAJ&amp;hl=zh-CN"><font color="#c60b0b">Academic service</font></a></strong></h2>
<h4><font color="#537abb">Reviewer for Conferences</font></h4>
<ul>
<li>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</li>
<li>International Conference on Computer Vision (<strong>ICCV</strong>)</li>
</ul>
</body></html>